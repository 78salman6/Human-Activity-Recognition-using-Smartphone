{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 563) (2947, 563)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../train.csv')\n",
    "test = pd.read_csv('../test.csv')\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "      <th>tBodyAcc-mean()-Y</th>\n",
       "      <th>tBodyAcc-mean()-Z</th>\n",
       "      <th>tBodyAcc-std()-X</th>\n",
       "      <th>tBodyAcc-std()-Y</th>\n",
       "      <th>tBodyAcc-std()-Z</th>\n",
       "      <th>tBodyAcc-mad()-X</th>\n",
       "      <th>tBodyAcc-mad()-Y</th>\n",
       "      <th>tBodyAcc-mad()-Z</th>\n",
       "      <th>tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
       "      <th>angle(tBodyAccMean,gravity)</th>\n",
       "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
       "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
       "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
       "      <th>angle(X,gravityMean)</th>\n",
       "      <th>angle(Y,gravityMean)</th>\n",
       "      <th>angle(Z,gravityMean)</th>\n",
       "      <th>subject</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288585</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.913526</td>\n",
       "      <td>-0.995112</td>\n",
       "      <td>-0.983185</td>\n",
       "      <td>-0.923527</td>\n",
       "      <td>-0.934724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.710304</td>\n",
       "      <td>-0.112754</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>-0.464761</td>\n",
       "      <td>-0.018446</td>\n",
       "      <td>-0.841247</td>\n",
       "      <td>0.179941</td>\n",
       "      <td>-0.058627</td>\n",
       "      <td>1</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278419</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>-0.123520</td>\n",
       "      <td>-0.998245</td>\n",
       "      <td>-0.975300</td>\n",
       "      <td>-0.960322</td>\n",
       "      <td>-0.998807</td>\n",
       "      <td>-0.974914</td>\n",
       "      <td>-0.957686</td>\n",
       "      <td>-0.943068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.861499</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>-0.844788</td>\n",
       "      <td>0.180289</td>\n",
       "      <td>-0.054317</td>\n",
       "      <td>1</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279653</td>\n",
       "      <td>-0.019467</td>\n",
       "      <td>-0.113462</td>\n",
       "      <td>-0.995380</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>-0.978944</td>\n",
       "      <td>-0.996520</td>\n",
       "      <td>-0.963668</td>\n",
       "      <td>-0.977469</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.760104</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.848933</td>\n",
       "      <td>0.180637</td>\n",
       "      <td>-0.049118</td>\n",
       "      <td>1</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279174</td>\n",
       "      <td>-0.026201</td>\n",
       "      <td>-0.123283</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.983403</td>\n",
       "      <td>-0.990675</td>\n",
       "      <td>-0.997099</td>\n",
       "      <td>-0.982750</td>\n",
       "      <td>-0.989302</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.482845</td>\n",
       "      <td>-0.036788</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.848649</td>\n",
       "      <td>0.181935</td>\n",
       "      <td>-0.047663</td>\n",
       "      <td>1</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276629</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>-0.998139</td>\n",
       "      <td>-0.980817</td>\n",
       "      <td>-0.990482</td>\n",
       "      <td>-0.998321</td>\n",
       "      <td>-0.979672</td>\n",
       "      <td>-0.990441</td>\n",
       "      <td>-0.942469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.699205</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.122542</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.847865</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>-0.043892</td>\n",
       "      <td>1</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  tBodyAcc-std()-X  \\\n",
       "0           0.288585          -0.020294          -0.132905         -0.995279   \n",
       "1           0.278419          -0.016411          -0.123520         -0.998245   \n",
       "2           0.279653          -0.019467          -0.113462         -0.995380   \n",
       "3           0.279174          -0.026201          -0.123283         -0.996091   \n",
       "4           0.276629          -0.016570          -0.115362         -0.998139   \n",
       "\n",
       "   tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  tBodyAcc-mad()-Y  \\\n",
       "0         -0.983111         -0.913526         -0.995112         -0.983185   \n",
       "1         -0.975300         -0.960322         -0.998807         -0.974914   \n",
       "2         -0.967187         -0.978944         -0.996520         -0.963668   \n",
       "3         -0.983403         -0.990675         -0.997099         -0.982750   \n",
       "4         -0.980817         -0.990482         -0.998321         -0.979672   \n",
       "\n",
       "   tBodyAcc-mad()-Z  tBodyAcc-max()-X    ...     \\\n",
       "0         -0.923527         -0.934724    ...      \n",
       "1         -0.957686         -0.943068    ...      \n",
       "2         -0.977469         -0.938692    ...      \n",
       "3         -0.989302         -0.938692    ...      \n",
       "4         -0.990441         -0.942469    ...      \n",
       "\n",
       "   fBodyBodyGyroJerkMag-kurtosis()  angle(tBodyAccMean,gravity)  \\\n",
       "0                        -0.710304                    -0.112754   \n",
       "1                        -0.861499                     0.053477   \n",
       "2                        -0.760104                    -0.118559   \n",
       "3                        -0.482845                    -0.036788   \n",
       "4                        -0.699205                     0.123320   \n",
       "\n",
       "   angle(tBodyAccJerkMean),gravityMean)  angle(tBodyGyroMean,gravityMean)  \\\n",
       "0                              0.030400                         -0.464761   \n",
       "1                             -0.007435                         -0.732626   \n",
       "2                              0.177899                          0.100699   \n",
       "3                             -0.012892                          0.640011   \n",
       "4                              0.122542                          0.693578   \n",
       "\n",
       "   angle(tBodyGyroJerkMean,gravityMean)  angle(X,gravityMean)  \\\n",
       "0                             -0.018446             -0.841247   \n",
       "1                              0.703511             -0.844788   \n",
       "2                              0.808529             -0.848933   \n",
       "3                             -0.485366             -0.848649   \n",
       "4                             -0.615971             -0.847865   \n",
       "\n",
       "   angle(Y,gravityMean)  angle(Z,gravityMean)  subject  Activity  \n",
       "0              0.179941             -0.058627        1  STANDING  \n",
       "1              0.180289             -0.054317        1  STANDING  \n",
       "2              0.180637             -0.049118        1  STANDING  \n",
       "3              0.181935             -0.047663        1  STANDING  \n",
       "4              0.185151             -0.043892        1  STANDING  \n",
       "\n",
       "[5 rows x 563 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C=1,random_state=0)\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X_train = train.iloc[:,:-2]\n",
    "Y_train = train['Activity']\n",
    "le = LabelEncoder()\n",
    "le.fit(['STANDING', 'SITTING', 'LAYING', 'WALKING', 'WALKING_DOWNSTAIRS','WALKING_UPSTAIRS'] )\n",
    "Y_train_encoded = le.transform(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = test.iloc[:,:-2]\n",
    "Y_test = test['Activity']\n",
    "Y_test_encoded = le.transform(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training model using all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Train Accuracy : 0.9908868335146899\n",
      "Logistic Regression Test Accuracy : 0.9619952494061758\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train,Y_train_encoded)\n",
    "print (\"Logistic Regression Train Accuracy : {}\".format(accuracy_score(Y_train_encoded,lr.predict(X_train))))\n",
    "print (\"Logistic Regression Test Accuracy : {}\".format(accuracy_score(Y_test_encoded,lr.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Choosing the value of regularization parameter, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 : 0.8819138106549033\n",
      "0.01 : 0.9379029521547336\n",
      "0.1 : 0.9582626399728538\n",
      "1 : 0.9619952494061758\n",
      "10 : 0.9619952494061758\n",
      "100 : 0.9619952494061758\n",
      "1000 : 0.9606379368849678\n"
     ]
    }
   ],
   "source": [
    "test_scores = []\n",
    "for i in [0.001,0.01,0.1,1,10,100,1000]:\n",
    "    lr = LogisticRegression(C=i)\n",
    "    lr.fit(X_train,Y_train_encoded)\n",
    "    acc = accuracy_score(Y_test_encoded,lr.predict(X_test))\n",
    "    test_scores.append(acc)\n",
    "    print(\"{} : {}\".format(i,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbgAAAE9CAYAAAB5t3fYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ace5d256d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.xlabel('Regularization Parameter : C')\n",
    "plt.ylabel('Accuracy')\n",
    "sns.barplot([0.001,0.01,0.1,1,10,100,1000],test_scores,palette='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training model with C = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=10)\n",
    "lr.fit(X_train,Y_train_encoded)\n",
    "print (\"Logistic Regression Train Accuracy : {}\".format(accuracy_score(Y_train_encoded,lr.predict(X_train))))\n",
    "print (\"Logistic Regression Test Accuracy : {}\".format(accuracy_score(Y_test_encoded,lr.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "X_train = train.iloc[:,:-2]\n",
    "X_test = test.iloc[:,:-2]\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print(X_train.shape,X_train_pca.shape)\n",
    "print(X_test.shape,X_test_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression().fit(X_train_pca,Y_train_encoded)\n",
    "print (\"Logistic Regression Train Accuracy : {}\".format(accuracy_score(Y_train_encoded,lr.predict(X_train_pca))))\n",
    "print (\"Logistic Regression Test Accuracy : {}\".format(accuracy_score(Y_test_encoded,lr.predict(X_test_pca))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Selecting the number of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = range(10,251,10)\n",
    "pca_scores = []\n",
    "for i in r:\n",
    "    pca = PCA(n_components=i,random_state=0).fit(X_train)\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    lr = LogisticRegression().fit(X_train_pca,Y_train_encoded)\n",
    "    acc = accuracy_score(Y_test_encoded,lr.predict(X_test_pca))\n",
    "    pca_scores.append(acc)\n",
    "    print(\"{} : {}\".format(i,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.xlabel('n_components in PCA')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.scatter(range(10,260,10),pca_scores)\n",
    "plt.xticks(range(10,260,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=200,random_state=0).fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "lr = LogisticRegression(random_state=0).fit(X_train_pca,Y_train_encoded)\n",
    "print (\"Logistic Regression Train Accuracy : {}\".format(accuracy_score(Y_train_encoded,lr.predict(X_train_pca))))\n",
    "print (\"Logistic Regression Test Accuracy : {}\".format(accuracy_score(Y_test_encoded,lr.predict(X_test_pca))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Selecting the value of regularization parameter, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_test_scores = []\n",
    "for i in [0.001,0.01,0.1,1,10,100,1000]:\n",
    "    lr = LogisticRegression(C=i,random_state=0)\n",
    "    lr.fit(X_train_pca,Y_train_encoded)\n",
    "    acc = accuracy_score(Y_test_encoded,lr.predict(X_test_pca))\n",
    "    pca_test_scores.append(acc)\n",
    "    print(\"{} : {}\".format(i,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.xlabel('Regularization Parameter : C')\n",
    "plt.ylabel('Accuracy')\n",
    "sns.barplot([0.001,0.01,0.1,1,10,100,1000],pca_test_scores,palette=\"rocket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training model with C = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=100,random_state=0)\n",
    "lr.fit(X_train_pca,Y_train_encoded)\n",
    "print (\"Logistic Regression Train Accuracy : {}\".format(accuracy_score(Y_train_encoded,lr.predict(X_train_pca))))\n",
    "print (\"Logistic Regression Test Accuracy : {}\".format(accuracy_score(Y_test_encoded,lr.predict(X_test_pca))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
